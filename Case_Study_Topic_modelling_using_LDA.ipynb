{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Case_Study_Topic_modelling_using_LDA.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anshupandey/xebia_training_data/blob/main/Case_Study_Topic_modelling_using_LDA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mennIfwaZ5rz"
      },
      "source": [
        "# Installation and Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uIQ7huAIZ5r4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 609
        },
        "outputId": "664e05e7-bf74-4dda-9c6b-6582aa7c8a00"
      },
      "source": [
        "# install below packages if not available\n",
        "!pip install gensim\n",
        "!pip install spaCy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.6/dist-packages (3.6.0)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.17.5)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.12.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.4.1)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.9.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.21.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (1.11.15)\n",
            "Requirement already satisfied: boto>=2.32 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.49.0)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2019.11.28)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (1.24.3)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.3.3)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.9.4)\n",
            "Requirement already satisfied: botocore<1.15.0,>=1.14.15 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (1.14.15)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->smart-open>=1.2.1->gensim) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->smart-open>=1.2.1->gensim) (2.6.1)\n",
            "Requirement already satisfied: spaCy in /usr/local/lib/python3.6/dist-packages (2.1.9)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spaCy) (1.0.2)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spaCy) (1.17.5)\n",
            "Requirement already satisfied: blis<0.3.0,>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from spaCy) (0.2.4)\n",
            "Requirement already satisfied: thinc<7.1.0,>=7.0.8 in /usr/local/lib/python3.6/dist-packages (from spaCy) (7.0.8)\n",
            "Requirement already satisfied: plac<1.0.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spaCy) (0.9.6)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spaCy) (2.21.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from spaCy) (0.6.0)\n",
            "Requirement already satisfied: preshed<2.1.0,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from spaCy) (2.0.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spaCy) (2.0.3)\n",
            "Requirement already satisfied: srsly<1.1.0,>=0.0.6 in /usr/local/lib/python3.6/dist-packages (from spaCy) (1.0.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<7.1.0,>=7.0.8->spaCy) (4.28.1)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spaCy) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spaCy) (2019.11.28)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spaCy) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spaCy) (1.24.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m8OVevbkZ5sC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "outputId": "6743c079-d1b9-465f-de45-a63e119f18b7"
      },
      "source": [
        "# download the corpus for nltk and spacy's english language model\n",
        "import nltk\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"wordnet\")\n",
        "nltk.download(\"stopwords\")\n",
        "!python -m spacy download en"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "Requirement already satisfied: en_core_web_sm==2.1.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.1.0/en_core_web_sm-2.1.0.tar.gz#egg=en_core_web_sm==2.1.0 in /usr/local/lib/python3.6/dist-packages (2.1.0)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/en_core_web_sm -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/en\n",
            "You can now load the model via spacy.load('en')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8BoxQpGaGlh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 644
        },
        "outputId": "0699210d-f53e-4d5a-c015-66c709fb56d9"
      },
      "source": [
        "!pip install pyLDAvis"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyLDAvis\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a5/3a/af82e070a8a96e13217c8f362f9a73e82d61ac8fff3a2561946a97f96266/pyLDAvis-2.1.2.tar.gz (1.6MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6MB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.23.0 in /usr/local/lib/python3.6/dist-packages (from pyLDAvis) (0.34.2)\n",
            "Requirement already satisfied: numpy>=1.9.2 in /usr/local/lib/python3.6/dist-packages (from pyLDAvis) (1.17.5)\n",
            "Requirement already satisfied: scipy>=0.18.0 in /usr/local/lib/python3.6/dist-packages (from pyLDAvis) (1.4.1)\n",
            "Requirement already satisfied: pandas>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from pyLDAvis) (0.25.3)\n",
            "Requirement already satisfied: joblib>=0.8.4 in /usr/local/lib/python3.6/dist-packages (from pyLDAvis) (0.14.1)\n",
            "Requirement already satisfied: jinja2>=2.7.2 in /usr/local/lib/python3.6/dist-packages (from pyLDAvis) (2.11.1)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.6/dist-packages (from pyLDAvis) (2.7.1)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.6/dist-packages (from pyLDAvis) (3.6.4)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyLDAvis) (0.16.0)\n",
            "Collecting funcy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ce/4b/6ffa76544e46614123de31574ad95758c421aae391a1764921b8a81e1eae/funcy-1.14.tar.gz (548kB)\n",
            "\u001b[K     |████████████████████████████████| 552kB 48.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.17.0->pyLDAvis) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.17.0->pyLDAvis) (2.6.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2>=2.7.2->pyLDAvis) (1.1.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis) (45.1.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis) (1.12.0)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis) (1.3.0)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis) (1.8.1)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis) (0.7.1)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis) (8.2.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis) (19.3.0)\n",
            "Building wheels for collected packages: pyLDAvis, funcy\n",
            "  Building wheel for pyLDAvis (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyLDAvis: filename=pyLDAvis-2.1.2-py2.py3-none-any.whl size=97711 sha256=637c5bddd0921c8cab1ee7e859a81c8b670094853bf0db671e5e816d4cab9b8a\n",
            "  Stored in directory: /root/.cache/pip/wheels/98/71/24/513a99e58bb6b8465bae4d2d5e9dba8f0bef8179e3051ac414\n",
            "  Building wheel for funcy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for funcy: filename=funcy-1.14-py2.py3-none-any.whl size=32042 sha256=fcdcdde5378ecbedc83a00faf431270deca47d09fc3650c084eb596a57f943f6\n",
            "  Stored in directory: /root/.cache/pip/wheels/20/5a/d8/1d875df03deae6f178dfdf70238cca33f948ef8a6f5209f2eb\n",
            "Successfully built pyLDAvis funcy\n",
            "Installing collected packages: funcy, pyLDAvis\n",
            "Successfully installed funcy-1.14 pyLDAvis-2.1.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xbQgSDGZ5sJ"
      },
      "source": [
        "# importing packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Ao9VNJjZ5sM"
      },
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# GENSIM\n",
        "import gensim\n",
        "import gensim.corpora as corpora\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.models import CoherenceModel\n",
        "\n",
        "# Plotting tools\n",
        "import pyLDAvis\n",
        "import pyLDAvis.gensim  # don't skip this\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
        "\n",
        "import spacy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CvvI8PGjZ5sl"
      },
      "source": [
        "# importing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQHMUD26Z5so",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "f3bcce2b-d088-4c60-abe9-0aea03709b93"
      },
      "source": [
        "# importing newsgroup data\n",
        "from sklearn import datasets\n",
        "emaildata = datasets.fetch_20newsgroups()\n",
        "data = emaildata.data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading 20news dataset. This may take a few minutes.\n",
            "Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZ1jqBlsZ5sv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5c46beda-a759-4b61-ad3f-fe593fac20c0"
      },
      "source": [
        "len(data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11314"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "ERplKM5SZ5s7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 641
        },
        "outputId": "0c81a780-9a46-4373-ba20-693e76c7ee23"
      },
      "source": [
        "print(data[11000])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "From: yamauchi@ces.cwru.edu (Brian Yamauchi)\n",
            "Subject: DC-X: Choice of a New Generation (was Re: SSRT Roll-Out Speech)\n",
            "Organization: Case Western Reserve University\n",
            "Lines: 27\n",
            "Distribution: world\n",
            "NNTP-Posting-Host: yuggoth.ces.cwru.edu\n",
            "In-reply-to: jkatz@access.digex.com's message of 21 Apr 1993 22:09:32 -0400\n",
            "\n",
            "In article <1r4uos$jid@access.digex.net> jkatz@access.digex.com (Jordan Katz) writes:\n",
            "\n",
            ">\t\t   Speech Delivered by Col. Simon P. Worden,\n",
            ">\t\t\tThe Deputy for Technology, SDIO\n",
            ">\n",
            ">\tMost of you, as am I, are \"children of the 1960's.\"  We grew\n",
            ">up in an age of miracles -- Inter-Continental Ballistic Missiles,\n",
            ">nuclear energy, computers, flights to the moon.  But these were\n",
            ">miracles of our parent's doing. \n",
            "\n",
            ">                          Speech by Pete Worden\n",
            ">          Delivered Before the U.S. Space Foundation Conference\n",
            "\n",
            ">     I'm embarrassed when my generation is compared with the last\n",
            ">generation -- the giants of the last great space era, the 1950's\n",
            ">and 1960's.  They went to the moon - we built a telescope that\n",
            ">can't see straight.  They soft-landed on Mars - the least we\n",
            ">could do is soft-land on Earth!\n",
            "\n",
            "Just out of curiousity, how old is Worden?\n",
            "--\n",
            "_______________________________________________________________________________\n",
            "\n",
            "Brian Yamauchi\t\t\tCase Western Reserve University\n",
            "yamauchi@alpha.ces.cwru.edu\tDepartment of Computer Engineering and Science\n",
            "_______________________________________________________________________________\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RjDY7sMgZ5tS"
      },
      "source": [
        "# Data Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4UB2VOcZZ5tU"
      },
      "source": [
        "# NLTK Stop words\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = stopwords.words('english')\n",
        "stop_words.extend(['from', 'subject', 're', 'edu', 'use'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0TU2ftCMZ5tb"
      },
      "source": [
        "# Remove Emails\n",
        "data = [re.sub('\\S*@\\S*\\s?', '', sent) for sent in data]\n",
        "\n",
        "# Remove new line characters\n",
        "data = [re.sub('\\s+', ' ', sent) for sent in data]\n",
        "\n",
        "# Remove distracting single quotes\n",
        "data = [re.sub(\"\\'\", \"\", sent) for sent in data]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdkGBOeSZ5tq"
      },
      "source": [
        "## Tokenize words and Clean-up text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLxg1Y29Z5tt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "3e6f06d8-fc0f-4a0a-c416-d4f71ce04eb5"
      },
      "source": [
        "def sent_to_words(sentences):\n",
        "    for sentence in sentences:\n",
        "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n",
        "\n",
        "data_words = list(sent_to_words(data))\n",
        "\n",
        "print(data_words[:1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['from', 'wheres', 'my', 'thing', 'subject', 'what', 'car', 'is', 'this', 'nntp', 'posting', 'host', 'rac', 'wam', 'umd', 'edu', 'organization', 'university', 'of', 'maryland', 'college', 'park', 'lines', 'was', 'wondering', 'if', 'anyone', 'out', 'there', 'could', 'enlighten', 'me', 'on', 'this', 'car', 'saw', 'the', 'other', 'day', 'it', 'was', 'door', 'sports', 'car', 'looked', 'to', 'be', 'from', 'the', 'late', 'early', 'it', 'was', 'called', 'bricklin', 'the', 'doors', 'were', 'really', 'small', 'in', 'addition', 'the', 'front', 'bumper', 'was', 'separate', 'from', 'the', 'rest', 'of', 'the', 'body', 'this', 'is', 'all', 'know', 'if', 'anyone', 'can', 'tellme', 'model', 'name', 'engine', 'specs', 'years', 'of', 'production', 'where', 'this', 'car', 'is', 'made', 'history', 'or', 'whatever', 'info', 'you', 'have', 'on', 'this', 'funky', 'looking', 'car', 'please', 'mail', 'thanks', 'il', 'brought', 'to', 'you', 'by', 'your', 'neighborhood', 'lerxst']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zzWo4Jq4Z5t0"
      },
      "source": [
        "# Creating Bigram and Trigram Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RY_SIwpLZ5uM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "6af8404a-2e56-4421-cdc3-3e35f42767a6"
      },
      "source": [
        "# Build the bigram and trigram models\n",
        "bigram = gensim.models.Phrases(data_words, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
        "trigram = gensim.models.Phrases(bigram[data_words], threshold=100)  \n",
        "\n",
        "# Faster way to get a sentence clubbed as a trigram/bigram\n",
        "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
        "trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
        "\n",
        "# See trigram example\n",
        "print(trigram_mod[bigram_mod[data_words[0]]])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
            "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "['from', 'wheres', 'my', 'thing', 'subject', 'what', 'car', 'is', 'this', 'nntp_posting_host', 'rac_wam_umd_edu', 'organization', 'university', 'of', 'maryland_college_park', 'lines', 'was', 'wondering', 'if', 'anyone', 'out', 'there', 'could', 'enlighten', 'me', 'on', 'this', 'car', 'saw', 'the', 'other', 'day', 'it', 'was', 'door', 'sports', 'car', 'looked', 'to', 'be', 'from', 'the', 'late', 'early', 'it', 'was', 'called', 'bricklin', 'the', 'doors', 'were', 'really', 'small', 'in', 'addition', 'the', 'front_bumper', 'was', 'separate', 'from', 'the', 'rest', 'of', 'the', 'body', 'this', 'is', 'all', 'know', 'if', 'anyone', 'can', 'tellme', 'model', 'name', 'engine', 'specs', 'years', 'of', 'production', 'where', 'this', 'car', 'is', 'made', 'history', 'or', 'whatever', 'info', 'you', 'have', 'on', 'this', 'funky', 'looking', 'car', 'please', 'mail', 'thanks', 'il', 'brought', 'to', 'you', 'by', 'your', 'neighborhood', 'lerxst']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2dWVIQOXZ5uT"
      },
      "source": [
        "# Remove Stopwords, Make Bigrams and Lemmatize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5yU68uApZ5uZ"
      },
      "source": [
        "# Define functions for stopwords, bigrams, trigrams and lemmatization\n",
        "def remove_stopwords(texts):\n",
        "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
        "\n",
        "def make_bigrams(texts):\n",
        "    return [bigram_mod[doc] for doc in texts]\n",
        "\n",
        "def make_trigrams(texts):\n",
        "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
        "\n",
        "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
        "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
        "    texts_out = []\n",
        "    for sent in texts:\n",
        "        doc = nlp(\" \".join(sent)) \n",
        "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
        "    return texts_out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vkmefd0_Z5uf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "1ea5461d-5e8d-47dc-b6c7-397fafdc4046"
      },
      "source": [
        "# Remove Stop Words\n",
        "data_words_nostops = remove_stopwords(data_words)\n",
        "\n",
        "# Form Bigrams\n",
        "data_words_bigrams = make_bigrams(data_words_nostops)\n",
        "\n",
        "# Initialize spacy 'en' model, keeping only tagger component (for efficiency)\n",
        "# python3 -m spacy download en\n",
        "nlp = spacy.load('en', disable=['parser', 'ner'])\n",
        "\n",
        "# Do lemmatization keeping only noun, adj, vb, adv\n",
        "data_lemmatized = lemmatization(data_words_bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
        "\n",
        "print(data_lemmatized[:1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['where', 's', 'thing', 'car', 'nntp_poste', 'host', 'umd', 'organization', 'university', 'maryland_college', 'park', 'line', 'wonder', 'anyone', 'could', 'enlighten', 'car', 'see', 'day', 'door', 'sport', 'car', 'look', 'late', 'early', 'call', 'bricklin', 'door', 'really', 'small', 'addition', 'front_bumper', 'separate', 'rest', 'body', 'know', 'anyone', 'tellme', 'model', 'name', 'engine', 'specs', 'year', 'production', 'car', 'make', 'history', 'info', 'funky', 'look', 'car', 'mail', 'thank', 'bring', 'neighborhood', 'lerxst']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dvTqA52lZ5um"
      },
      "source": [
        "# Topic Modeling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xUmt5AbbZ5uo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "99734cf8-20d2-40fa-910a-a18ddedafbba"
      },
      "source": [
        "# Create Dictionary\n",
        "dictionary = corpora.Dictionary(data_lemmatized)\n",
        "\n",
        "# Create Corpus\n",
        "texts = data_lemmatized\n",
        "\n",
        "# Term Document Frequency\n",
        "corpus = [dictionary.doc2bow(text) for text in texts]\n",
        "\n",
        "# View\n",
        "print(corpus[:1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[(0, 1), (1, 2), (2, 1), (3, 1), (4, 1), (5, 1), (6, 5), (7, 1), (8, 1), (9, 2), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 2), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1), (34, 1), (35, 1), (36, 1), (37, 1), (38, 1), (39, 1), (40, 1), (41, 1), (42, 1), (43, 1), (44, 1), (45, 1), (46, 1), (47, 1), (48, 1)]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqL7-3-KZ5uv"
      },
      "source": [
        "# Build LDA model\n",
        "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
        "                                           id2word=dictionary,\n",
        "                                           num_topics=20, \n",
        "                                           random_state=100,\n",
        "                                           update_every=1,\n",
        "                                           chunksize=100,\n",
        "                                           passes=10,\n",
        "                                           alpha='auto',\n",
        "                                           per_word_topics=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdAGui8UZ5u3"
      },
      "source": [
        "# View the topics in LDA model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LgFX9gWtZ5u5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "91f099a5-7bb6-44c8-d9bd-3cc07ef25569"
      },
      "source": [
        "# Print the Keyword in the 10 topics\n",
        "print(lda_model.print_topics())\n",
        "doc_lda = lda_model[corpus]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(0, '0.036*\"team\" + 0.036*\"game\" + 0.020*\"sale\" + 0.019*\"play\" + 0.015*\"hockey\" + 0.012*\"year\" + 0.008*\"nhl\" + 0.008*\"trade\" + 0.008*\"wing\" + 0.007*\"steven\"'), (1, '0.040*\"book\" + 0.020*\"belief\" + 0.020*\"atheist\" + 0.018*\"church\" + 0.015*\"pin\" + 0.015*\"slave\" + 0.014*\"sphere\" + 0.012*\"character\" + 0.010*\"lord\" + 0.009*\"headache\"'), (2, '0.015*\"choose\" + 0.012*\"input\" + 0.011*\"sin\" + 0.010*\"notice\" + 0.009*\"eat\" + 0.009*\"cd\" + 0.009*\"food\" + 0.009*\"material\" + 0.008*\"signal\" + 0.008*\"external\"'), (3, '0.035*\"not\" + 0.022*\"write\" + 0.022*\"do\" + 0.020*\"would\" + 0.020*\"line\" + 0.019*\"organization\" + 0.017*\"be\" + 0.017*\"article\" + 0.014*\"get\" + 0.014*\"know\"'), (4, '0.533*\"ax\" + 0.008*\"rlk\" + 0.006*\"cub\" + 0.005*\"echo\" + 0.004*\"tufts_university\" + 0.004*\"stl\" + 0.004*\"pitcher\" + 0.004*\"pit\" + 0.004*\"lk\" + 0.003*\"differential\"'), (5, '0.027*\"israel\" + 0.015*\"israeli\" + 0.011*\"jew\" + 0.009*\"lebanese\" + 0.009*\"arab\" + 0.009*\"jewish\" + 0.009*\"war\" + 0.008*\"death\" + 0.008*\"kill\" + 0.007*\"attack\"'), (6, '0.030*\"drive\" + 0.018*\"card\" + 0.014*\"mac\" + 0.013*\"driver\" + 0.012*\"system\" + 0.011*\"cpu\" + 0.009*\"memory\" + 0.009*\"computer\" + 0.009*\"chip\" + 0.009*\"use\"'), (7, '0.053*\"_\" + 0.045*\"max\" + 0.012*\"dn\" + 0.010*\"eeg\" + 0.009*\"cx\" + 0.007*\"c\" + 0.007*\"mv\" + 0.005*\"mk\" + 0.005*\"sw\" + 0.004*\"mj\"'), (8, '0.015*\"library\" + 0.015*\"section\" + 0.013*\"st\" + 0.011*\"ed\" + 0.009*\"title\" + 0.009*\"art\" + 0.009*\"author\" + 0.009*\"pa\" + 0.009*\"translation\" + 0.009*\"page\"'), (9, '0.017*\"car\" + 0.011*\"new\" + 0.009*\"buy\" + 0.009*\"physical\" + 0.008*\"power\" + 0.008*\"type\" + 0.007*\"old\" + 0.007*\"graphic\" + 0.007*\"screen\" + 0.007*\"good\"'), (10, '0.035*\"god\" + 0.021*\"evidence\" + 0.017*\"christian\" + 0.015*\"reason\" + 0.015*\"believe\" + 0.012*\"say\" + 0.011*\"faith\" + 0.010*\"claim\" + 0.010*\"exist\" + 0.010*\"sense\"'), (11, '0.019*\"university\" + 0.017*\"organization\" + 0.015*\"line\" + 0.014*\"instal\" + 0.011*\"michael\" + 0.010*\"format\" + 0.010*\"package\" + 0.010*\"problem\" + 0.009*\"distribution\" + 0.009*\"robert\"'), (12, '0.018*\"pay\" + 0.015*\"item\" + 0.014*\"service\" + 0.012*\"cover\" + 0.012*\"cost\" + 0.011*\"sell\" + 0.010*\"recommend\" + 0.010*\"replace\" + 0.009*\"gateway\" + 0.009*\"air\"'), (13, '0.019*\"line\" + 0.017*\"window\" + 0.016*\"mail\" + 0.016*\"file\" + 0.016*\"thank\" + 0.015*\"program\" + 0.013*\"use\" + 0.011*\"organization\" + 0.011*\"system\" + 0.009*\"email\"'), (14, '0.019*\"state\" + 0.012*\"law\" + 0.012*\"issue\" + 0.011*\"right\" + 0.010*\"case\" + 0.008*\"group\" + 0.006*\"new\" + 0.005*\"people\" + 0.005*\"national\" + 0.005*\"support\"'), (15, '0.025*\"internet\" + 0.020*\"bike\" + 0.017*\"server\" + 0.014*\"md\" + 0.013*\"com\" + 0.012*\"engine\" + 0.011*\"ride\" + 0.011*\"steve\" + 0.011*\"pain\" + 0.010*\"route\"'), (16, '0.019*\"gun\" + 0.010*\"kill\" + 0.010*\"people\" + 0.009*\"armenian\" + 0.008*\"say\" + 0.008*\"fire\" + 0.008*\"child\" + 0.007*\"greek\" + 0.006*\"government\" + 0.006*\"american\"'), (17, '0.020*\"win\" + 0.016*\"year\" + 0.014*\"player\" + 0.013*\"university\" + 0.012*\"patient\" + 0.009*\"fan\" + 0.008*\"run\" + 0.008*\"drug\" + 0.007*\"score\" + 0.007*\"mouse\"'), (18, '0.027*\"space\" + 0.012*\"research\" + 0.009*\"faq\" + 0.008*\"earth\" + 0.008*\"mount\" + 0.007*\"science\" + 0.007*\"launch\" + 0.006*\"project\" + 0.006*\"moon\" + 0.006*\"datum\"'), (19, '0.041*\"key\" + 0.014*\"system\" + 0.014*\"ripem\" + 0.013*\"government\" + 0.013*\"public\" + 0.012*\"security\" + 0.012*\"encryption\" + 0.010*\"tape\" + 0.009*\"chip\" + 0.009*\"clipper\"')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "icT7lXGbtXWi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        },
        "outputId": "28180837-b137-4808-ce91-add07c5a3f49"
      },
      "source": [
        "lda_model.print_topics()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0,\n",
              "  '0.036*\"team\" + 0.036*\"game\" + 0.020*\"sale\" + 0.019*\"play\" + 0.015*\"hockey\" + 0.012*\"year\" + 0.008*\"nhl\" + 0.008*\"trade\" + 0.008*\"wing\" + 0.007*\"steven\"'),\n",
              " (1,\n",
              "  '0.040*\"book\" + 0.020*\"belief\" + 0.020*\"atheist\" + 0.018*\"church\" + 0.015*\"pin\" + 0.015*\"slave\" + 0.014*\"sphere\" + 0.012*\"character\" + 0.010*\"lord\" + 0.009*\"headache\"'),\n",
              " (2,\n",
              "  '0.015*\"choose\" + 0.012*\"input\" + 0.011*\"sin\" + 0.010*\"notice\" + 0.009*\"eat\" + 0.009*\"cd\" + 0.009*\"food\" + 0.009*\"material\" + 0.008*\"signal\" + 0.008*\"external\"'),\n",
              " (3,\n",
              "  '0.035*\"not\" + 0.022*\"write\" + 0.022*\"do\" + 0.020*\"would\" + 0.020*\"line\" + 0.019*\"organization\" + 0.017*\"be\" + 0.017*\"article\" + 0.014*\"get\" + 0.014*\"know\"'),\n",
              " (4,\n",
              "  '0.533*\"ax\" + 0.008*\"rlk\" + 0.006*\"cub\" + 0.005*\"echo\" + 0.004*\"tufts_university\" + 0.004*\"stl\" + 0.004*\"pitcher\" + 0.004*\"pit\" + 0.004*\"lk\" + 0.003*\"differential\"'),\n",
              " (5,\n",
              "  '0.027*\"israel\" + 0.015*\"israeli\" + 0.011*\"jew\" + 0.009*\"lebanese\" + 0.009*\"arab\" + 0.009*\"jewish\" + 0.009*\"war\" + 0.008*\"death\" + 0.008*\"kill\" + 0.007*\"attack\"'),\n",
              " (6,\n",
              "  '0.030*\"drive\" + 0.018*\"card\" + 0.014*\"mac\" + 0.013*\"driver\" + 0.012*\"system\" + 0.011*\"cpu\" + 0.009*\"memory\" + 0.009*\"computer\" + 0.009*\"chip\" + 0.009*\"use\"'),\n",
              " (7,\n",
              "  '0.053*\"_\" + 0.045*\"max\" + 0.012*\"dn\" + 0.010*\"eeg\" + 0.009*\"cx\" + 0.007*\"c\" + 0.007*\"mv\" + 0.005*\"mk\" + 0.005*\"sw\" + 0.004*\"mj\"'),\n",
              " (8,\n",
              "  '0.015*\"library\" + 0.015*\"section\" + 0.013*\"st\" + 0.011*\"ed\" + 0.009*\"title\" + 0.009*\"art\" + 0.009*\"author\" + 0.009*\"pa\" + 0.009*\"translation\" + 0.009*\"page\"'),\n",
              " (9,\n",
              "  '0.017*\"car\" + 0.011*\"new\" + 0.009*\"buy\" + 0.009*\"physical\" + 0.008*\"power\" + 0.008*\"type\" + 0.007*\"old\" + 0.007*\"graphic\" + 0.007*\"screen\" + 0.007*\"good\"'),\n",
              " (10,\n",
              "  '0.035*\"god\" + 0.021*\"evidence\" + 0.017*\"christian\" + 0.015*\"reason\" + 0.015*\"believe\" + 0.012*\"say\" + 0.011*\"faith\" + 0.010*\"claim\" + 0.010*\"exist\" + 0.010*\"sense\"'),\n",
              " (11,\n",
              "  '0.019*\"university\" + 0.017*\"organization\" + 0.015*\"line\" + 0.014*\"instal\" + 0.011*\"michael\" + 0.010*\"format\" + 0.010*\"package\" + 0.010*\"problem\" + 0.009*\"distribution\" + 0.009*\"robert\"'),\n",
              " (12,\n",
              "  '0.018*\"pay\" + 0.015*\"item\" + 0.014*\"service\" + 0.012*\"cover\" + 0.012*\"cost\" + 0.011*\"sell\" + 0.010*\"recommend\" + 0.010*\"replace\" + 0.009*\"gateway\" + 0.009*\"air\"'),\n",
              " (13,\n",
              "  '0.019*\"line\" + 0.017*\"window\" + 0.016*\"mail\" + 0.016*\"file\" + 0.016*\"thank\" + 0.015*\"program\" + 0.013*\"use\" + 0.011*\"organization\" + 0.011*\"system\" + 0.009*\"email\"'),\n",
              " (14,\n",
              "  '0.019*\"state\" + 0.012*\"law\" + 0.012*\"issue\" + 0.011*\"right\" + 0.010*\"case\" + 0.008*\"group\" + 0.006*\"new\" + 0.005*\"people\" + 0.005*\"national\" + 0.005*\"support\"'),\n",
              " (15,\n",
              "  '0.025*\"internet\" + 0.020*\"bike\" + 0.017*\"server\" + 0.014*\"md\" + 0.013*\"com\" + 0.012*\"engine\" + 0.011*\"ride\" + 0.011*\"steve\" + 0.011*\"pain\" + 0.010*\"route\"'),\n",
              " (16,\n",
              "  '0.019*\"gun\" + 0.010*\"kill\" + 0.010*\"people\" + 0.009*\"armenian\" + 0.008*\"say\" + 0.008*\"fire\" + 0.008*\"child\" + 0.007*\"greek\" + 0.006*\"government\" + 0.006*\"american\"'),\n",
              " (17,\n",
              "  '0.020*\"win\" + 0.016*\"year\" + 0.014*\"player\" + 0.013*\"university\" + 0.012*\"patient\" + 0.009*\"fan\" + 0.008*\"run\" + 0.008*\"drug\" + 0.007*\"score\" + 0.007*\"mouse\"'),\n",
              " (18,\n",
              "  '0.027*\"space\" + 0.012*\"research\" + 0.009*\"faq\" + 0.008*\"earth\" + 0.008*\"mount\" + 0.007*\"science\" + 0.007*\"launch\" + 0.006*\"project\" + 0.006*\"moon\" + 0.006*\"datum\"'),\n",
              " (19,\n",
              "  '0.041*\"key\" + 0.014*\"system\" + 0.014*\"ripem\" + 0.013*\"government\" + 0.013*\"public\" + 0.012*\"security\" + 0.012*\"encryption\" + 0.010*\"tape\" + 0.009*\"chip\" + 0.009*\"clipper\"')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vod5_bTmZ5u_"
      },
      "source": [
        "# Compute Model Coherence Score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LA15iJG2Z5vB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "a853739d-e695-40f5-e401-71938774c50b"
      },
      "source": [
        "# Compute Coherence Score\n",
        "coherence_model_lda = CoherenceModel(model=lda_model, texts=data_lemmatized, dictionary=dictionary, coherence='c_v')\n",
        "coherence_lda = coherence_model_lda.get_coherence()\n",
        "print('\\nCoherence Score: ', coherence_lda)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Coherence Score:  0.5017680246997409\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rz4HQG8QZ5vG"
      },
      "source": [
        "# Visualize the topics-keywords"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECiu3xU8Z5vI"
      },
      "source": [
        "# Visualize the topics\n",
        "pyLDAvis.enable_notebook()\n",
        "vis = pyLDAvis.gensim.prepare(lda_model, corpus, dictionary)\n",
        "vis"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1DRyS4jZ5vS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tj6sBBZ8Z5vd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4m7ijUy0Z5vi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9eR8RCiZ5vn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iEWPiZpSZ5vs"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXtnJf23Z5vy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRYQkBJNZ5v5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rAyLfgdNZ5wH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xV7iZS8QZ5wO"
      },
      "source": [
        "# LDA Mallet Model\n",
        "\n",
        "You can achive better performance with LDA Mallet model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhVIk9wmZ5wS",
        "outputId": "19f73900-e0c2-48ef-b987-152493990381"
      },
      "source": [
        "# Download File: http://mallet.cs.umass.edu/dist/mallet-2.0.8.zip\n",
        "mallet_path = r\"D:\\AI\\jpmc_mumbai\\mallet-2.0.8\\mallet-2.0.8\\bin\\mallet\" # update this path\n",
        "ldamallet = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=20, id2word=dictionary)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\anshu\\\\AppData\\\\Local\\\\Temp\\\\93da81_state.mallet.gz'",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-21-f8f36c7d330f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Download File: http://mallet.cs.umass.edu/dist/mallet-2.0.8.zip\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmallet_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mr\"D:\\AI\\jpmc_mumbai\\mallet-2.0.8\\mallet-2.0.8\\bin\\mallet\"\u001b[0m \u001b[1;31m# update this path\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mldamallet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgensim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrappers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLdaMallet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmallet_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_topics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mid2word\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\models\\wrappers\\ldamallet.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, mallet_path, corpus, num_topics, alpha, id2word, workers, prefix, optimize_interval, iterations, topic_threshold)\u001b[0m\n\u001b[0;32m    124\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterations\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miterations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcorpus\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 126\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    127\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfinferencer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\models\\wrappers\\ldamallet.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, corpus)\u001b[0m\n\u001b[0;32m    277\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"training MALLET LDA with %s\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    278\u001b[0m         \u001b[0mcheck_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcmd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshell\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 279\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword_topics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_word_topics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    280\u001b[0m         \u001b[1;31m# NOTE - we are still keeping the wordtopics variable to not break backward compatibility.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    281\u001b[0m         \u001b[1;31m# word_topics has replaced wordtopics throughout the code;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\models\\wrappers\\ldamallet.py\u001b[0m in \u001b[0;36mload_word_topics\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    335\u001b[0m             \u001b[0mword2id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrevdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mid2word\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    336\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 337\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msmart_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfstate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfin\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    338\u001b[0m             \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfin\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# header\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malpha\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mval\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfin\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\smart_open\\smart_open_lib.py\u001b[0m in \u001b[0;36msmart_open\u001b[1;34m(uri, mode, **kw)\u001b[0m\n\u001b[0;32m    229\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m         \u001b[0mbinary_mode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 231\u001b[1;33m     \u001b[0mbinary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_open_binary_stream\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muri\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbinary_mode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    232\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mignore_extension\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m         \u001b[0mdecompressed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbinary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\smart_open\\smart_open_lib.py\u001b[0m in \u001b[0;36m_open_binary_stream\u001b[1;34m(uri, mode, **kw)\u001b[0m\n\u001b[0;32m    333\u001b[0m             \u001b[1;31m# local files -- both read & write supported\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m             \u001b[1;31m# compression, if any, is determined by the filename extension (.gz, .bz2)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 335\u001b[1;33m             \u001b[0mfobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparsed_uri\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muri_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    336\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mfobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    337\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mparsed_uri\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscheme\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msmart_open_s3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSUPPORTED_SCHEMES\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\anshu\\\\AppData\\\\Local\\\\Temp\\\\93da81_state.mallet.gz'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7DIhTKPZ5wc"
      },
      "source": [
        "# Show Topics\n",
        "print(ldamallet.show_topics(formatted=False))\n",
        "\n",
        "# Compute Coherence Score\n",
        "coherence_model_ldamallet = CoherenceModel(model=ldamallet, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
        "coherence_ldamallet = coherence_model_ldamallet.get_coherence()\n",
        "print('\\nCoherence Score: ', coherence_ldamallet)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rGK9RAoeZ5wi"
      },
      "source": [
        "# finding the optimal number of topics for LDA?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Nd5-om2Z5wk"
      },
      "source": [
        "Choosing a ‘k’ that marks the end of a rapid growth of topic coherence usually offers meaningful and interpretable topics. Picking an even higher value can sometimes provide more granular sub-topics.\n",
        "\n",
        "If you see the same keywords being repeated in multiple topics, it’s probably a sign that the ‘k’ is too large."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ev0WG3yWZ5wm"
      },
      "source": [
        "def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=3):\n",
        "    \"\"\"\n",
        "    Compute c_v coherence for various number of topics\n",
        "\n",
        "    Parameters:\n",
        "    ----------\n",
        "    dictionary : Gensim dictionary\n",
        "    corpus : Gensim corpus\n",
        "    texts : List of input texts\n",
        "    limit : Max num of topics\n",
        "\n",
        "    Returns:\n",
        "    -------\n",
        "    model_list : List of LDA topic models\n",
        "    coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n",
        "    \"\"\"\n",
        "    coherence_values = []\n",
        "    model_list = []\n",
        "    for num_topics in range(start, limit, step):\n",
        "        model = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=num_topics, id2word=dictionary)\n",
        "        model_list.append(model)\n",
        "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
        "        coherence_values.append(coherencemodel.get_coherence())\n",
        "\n",
        "    return model_list, coherence_values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlpUXDMaZ5w7"
      },
      "source": [
        "# Can take a long time to run.\n",
        "model_list, coherence_values = compute_coherence_values(dictionary=dictionary, corpus=corpus, texts=data_lemmatized, start=2, limit=40, step=6)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbRHohIzZ5xB"
      },
      "source": [
        "# Show graph\n",
        "limit=40; start=2; step=6;\n",
        "x = range(start, limit, step)\n",
        "plt.plot(x, coherence_values)\n",
        "plt.xlabel(\"Num Topics\")\n",
        "plt.ylabel(\"Coherence score\")\n",
        "plt.legend((\"coherence_values\"), loc='best')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ml5LufiGZ5xG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}